{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import codecs as c\n",
    "from scipy.spatial.distance import cosine as csn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing of the raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with c.open(\"sentences.txt\",\"r\") as input_file:\n",
    "    input_data = \" \".join(input_file.readlines()).strip().lower()\n",
    "    sentences_matrix = [[x for x in re.split('[^a-z]', y) if x != \"\"] for y in input_data[:].split(\"\\n\")]\n",
    "    splited_data = re.split('[^a-z]', input_data)\n",
    "    tokenized_list = [x for x in splited_data if x != \"\"]\n",
    "#print(f\"The sentences' matrix in the lower case and splited. Empty string elements deleted:\\n\\n {sentences_matrix} \\n\\n\")\n",
    "#print(f\"The sentences' list in the lower case and splited. Empty string elements deleted:\\n\\n {tokenized_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dict of the diferent words which contain in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "count_dict = {}\n",
    "for item in tokenized_list:\n",
    "    if item not in count_dict:\n",
    "        count_dict[item] = 1\n",
    "    else:\n",
    "        count_dict[item] += 1\n",
    "\n",
    "print(len(count_dict))\n",
    "\"\"\"\n",
    "\n",
    "word_dict = {}\n",
    "i = 0\n",
    "\n",
    "for item in tokenized_list:\n",
    "    if item not in word_dict:\n",
    "        word_dict[item] = i\n",
    "        i += 1\n",
    "\n",
    "#print(word_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix of weights creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_i = word_dict.values()\n",
    "#print(*column_i)\n",
    "#w_matrix = [[lambda x,y: for z in y: word_dict[z] == x for x in column_i] for y in sentences_matrix]\n",
    "line_len = max(column_i) + 1\n",
    "column_len = len(sentences_matrix)\n",
    "w_matrix = np.array([[0 for _ in range(line_len)] for _ in range(column_len)])\n",
    "dict_keys = word_dict.keys()\n",
    "\n",
    "for line_o, line in enumerate(w_matrix):\n",
    "    sent_line = sentences_matrix[line_o]\n",
    "    for words in dict_keys:\n",
    "        for value in sent_line:\n",
    "            if value == words:\n",
    "                w_matrix[line_o][word_dict[words]] += 1\n",
    "\n",
    "# print(*w_matrix, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating cosine distance between the first and other sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0.0\n",
      "6:0.7327387580875756\n",
      "4:0.7770887149698589\n",
      "21:0.8250364469440588\n",
      "10:0.8328165362273942\n",
      "12:0.8396432548525454\n",
      "16:0.8406361854220809\n",
      "20:0.8427572744917122\n",
      "2:0.8644738145642124\n",
      "13:0.8703592552895671\n",
      "14:0.8740118423302576\n",
      "11:0.8804771390665607\n",
      "8:0.8842724875284311\n",
      "19:0.8885443574849294\n",
      "3:0.8951715163278082\n",
      "9:0.9055088817476932\n",
      "7:0.9258750683338899\n",
      "5:0.9402385695332803\n",
      "15:0.9442721787424647\n",
      "18:0.9442721787424647\n",
      "15:0.9442721787424647\n",
      "18:0.9442721787424647\n",
      "1:0.9527544408738466\n",
      "17:0.956644501523794\n"
     ]
    }
   ],
   "source": [
    "csn_dict = {}\n",
    "counter = 0\n",
    "for line in w_matrix:\n",
    "    csn_dict[counter] = csn(w_matrix[0], line)\n",
    "    counter += 1\n",
    "\n",
    "sorted_values = sorted(csn_dict.values())\n",
    "\n",
    "for items in sorted_values:\n",
    "    for key, value in csn_dict.items():\n",
    "        if csn_dict[key] == items:\n",
    "            print(f\"{key}:{items}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very closest sentences to 0th sentence are 6th and 4th sentences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
